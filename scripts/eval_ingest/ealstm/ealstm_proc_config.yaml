# setup for the Julie Mai xSSA datasets from 2022 Nature Comm pub
col_schema:   # required column mappings in the evaluation metrics dataset
  - 'gage_id': 'gageID' # The basin identifier/gage id used for each modeled location in the evaluation metrics dataset
  - 'featureID': 'USGS-{gage_id}' # python f-string / R glue() format; converting the 'gage_id' to the standardized featureID used by nhdplusTools. Must use '{gage_id}' e.g. 'USGS-{gage_id}'
  - 'featureSource': 'nwissite' # The standardized nhdplusTools featureSource. Possible featureSources might be 'nwissite', 'comid'.
  - 'metric_cols': 'NSE|alpha_nse|beta_nse|FHV|FLV|FMS|NNSE' # Column(s) in the dataset corresponding to the evaluation metrics. If multiple exist, separate each string by '|' e.g. 'rmse|kge|nse'
  - 'metric_mappings': 'NSE|alpha_NSE|beta_NSE|FHV|FLV|FMS|NNSE' # The mapping of metric_cols to the standardized format as specified in fs_categories.yaml, separate each metric name by '|' e.g. 'RMSE|KGE|NSE'
file_io: # May define {home_dir} for python's '{home_dir}/string_path'.format(home_dir =str(Path.home())) functionality
  - 'path_data': '{home_dir}/git/ealstm_regional_modeling/notebooks/all_metrics.p' # Where the raw input data are stored.
  - 'dir_save': '{home_dir}/noaa/regionalization/data/input/' # Required. The save location of standardized output
  - 'save_type': 'netcdf' #  Required. Save as hierarchical files 'netcdf' or 'zarr'. Default 'netcdf' until attribute 
  - 'save_loc': 'local' #  Required.  Use 'local' for saving to a local path via dir_save. Future work will create an approach for 'aws' or other cloud saving methods
formulation_metadata:  
  - 'dataset_name': 'kratzert19_{ds}' # Required. This defines the subdirectory 'dataset' name inside teh user_data_std directory. In this case, we'll create subdirectories for each dataset. See proc_ealstm_agu24.py
  - 'formulation_base': 'lstm_ealstm_vic_mhm_sacsma_hbv_fuse_kratzert2019' # Required. Basename of formulation. the rr, sp, and gw will be added to this if 'formulation_id' is left empty
  - 'formulation_id': 'no_single_seeds' # Optional alternative in lieu of generating a formulation_id based on 'formulation_base'. Should leave empty if automatic formulation_id generation desired. This is appended to the end of the netcdf filename
  - 'formulation_ver': '' # Optional. The version of the formulation
  - 'temporal_res': 'daily' # The temporal resolution corresponding to the modeled data
  - 'target_var': 'Q' # Required. The target variable modeled. This is standardized. See target_var_mappings in fs_categories.yaml
  - 'start_date': '1989-10-01' # Required. The YYYY-MM-DD start date corresponding to the evaluation metric's modeled timeseries
  - 'end_date':  '1999-09-30' # Required. The YYYY-MM-DD end date corresponding to the evaluation metric's modeled timeseries
  - 'modeled notes': '531 CAMELS basins, <2000km^2, and removed basins w/ >10% basin area calculation discrepancy per Newman et al 2017; only considering ensemble LSTM, n=8'
  - 'cal_status': 'Y' # Required. Was the formulation model fully calibrated? Options include 'Y','N', or 'S' (yes/no/somewhat)
  - 'start_date_cal': '1991-01-01' # The YYYY-MM-DD start date corresponding to the calibration period
  - 'end_date_cal': '2010-12-31' # The YYYY-MM-DD end date corresponding to the calibration period
  - 'cal_notes': 'Calibration on basins larger than 300 km2 and more than 5 years observed streamflow data'
references: # All optional but **very** helpful metadata
  - 'input_filepath': '{base_dir}/git/ealstm_regional_modeling/notebooks/all_metrics.p'
  - 'source_url': 'https://github.com/kratzert/ealstm_regional_modeling/blob/master/notebooks/all_metrics.p'
  - 'dataset_doi': ''
  - 'literature_doi': 'https://doi.org/10.5194/hess-23-5089-2019'
