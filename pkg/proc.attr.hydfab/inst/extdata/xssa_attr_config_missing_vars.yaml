# Config for grabbing catchment attributes corresponding to standard-named locations
# Two options exist for defining locations that need attributes. At least one must be used. Both may be used.
# 1. Refer to a file/dataset {loc_id_filepath} with a column identifer {loc_id} representing a standardized location identifier.
# 2. Refer to a dataset processed by fs_proc python package and point to its location, {dir_std_base}/{datasets}, where {datasets} is a specific subdirectory name(s) or simply 'all'

col_schema:   # required column mappings in the evaluation metrics dataset (if read in)
  - 'featureID': 'USGS-{gage_id}' # python f-string / R glue() format; converting the 'gage_id' to the standardized featureID used by nhdplusTools/hydrofabric. Must use '{gage_id}' e.g. 'USGS-{gage_id}'
  - 'featureSource': 'nwissite' # The standardized nhdplusTools featureSource. Possible featureSources might be 'nwissite', 'comid'.
loc_id_read: # This section only required for locations NOT to be read in under a standardized dataset location (dir_std_base). May be used for additional prediction locations. MUST leave each item name inside list with empty assignments if no datasets desired.
  - 'gage_id': 'gage_id' # expects tabular dataset with this column name representing the location id. Must be 1st item in this sublist.
  - 'loc_id_filepath': '{dir_std_base}/juliemai-xSSA/eval/metrics/juliemai-xSSA_Raven_blended.csv' #Filepath. Allows reading of .csv or a dataset accessible using arrow::open_datast(). Must be 2nd item in this sublist.
  - 'featureID_loc' : 'USGS-{gage_id}' # python f-string / R glue() format; converting the 'loc_id' to the standardized featureID used by nhdplusTools/hydrofabric. Must use '{loc_id}' e.g. 'USGS-{loc_id}'. Must be 3rd item in this sublist.
  - 'featureSource_loc': 'nwissite' # The standardized nhdplusTools featureSource. Must be 4th item in this sublist.
file_io: # May define {home_dir} for python's '{home_dir}/string_path'.format(home_dir =str(Path.home())) functionality
  - 'dir_save': '{home_dir}/noaa/regionalization/data/input' #TODO determine if this needed.
  - 'save_type': 'netcdf' #  Required. Use 'csv' to create a directory structure & save multiple files. May also save as hierarchical files 'netcdf' or 'zarr', or if 'csv' chosen, a directory structure is created
  - 'save_loc': 'local' #  Required.  Use 'local' for saving to a local path via dir_save. Future work will create an approach for 'aws' or other cloud saving methods
  - 'dir_base' : '{home_dir}/noaa/regionalization/data/input' # Required. The save location of standardized output
  - 'dir_std_base' : '{dir_base}/user_data_std' # Required. The location of standardized data generated by fs_proc python package
  - 'dir_db_hydfab' : '{dir_base}/hydrofabric' # Required. The local dir where hydrofabric data are stored (limits the total s3 connections)
  - 'dir_db_attrs' : '{dir_base}/attributes' # Required. The parent dir where each comid's attribute parquet file is stored in the subdirectory 'comid/', and each dataset's aggregated parquet attributes are stored in the subdirectory '/{dataset_name}
formulation_metadata:
  - 'datasets': # Required. Must match directory name inside dir_std_base. May be a list of items, or simply sublist 'all' to select everything inside dir_std_base for attribute grabbing.
    - 'juliemai-xSSA' # Required. In this example case, it's a sublist of just one thing.
  - 'formulation_base': 'Raven_blended' # Informational. Unique name of formulation.
hydfab_config: # Required section describing hydrofabric connection details and objects of interest
 - s3_base: "s3://lynker-spatial/tabular-resources" # Required. s3 path containing hydrofabric-formatted attribute datasets
 - s3_bucket: 'lynker-spatial' # Required. s3 bucket containing hydrofabric data
 - hf_cat_sel: "total" # Required. Options include 'total' or 'all'; total: interested in the single location's aggregated catchment data; all: all subcatchments of interest
 - gpkg:  # Optional. A local gpkg file. Default 'NULL'. See hfsubsetR::get_subset()
 - hfab_retr: FALSE # Optional, Boolean. Defaults to the hfab_retr argument default in the proc_attr_wrap() function (TRUE). Should the hydrofabric data be downloaded? Hydrofabric data download may not be necessary. Processing is faster if set to FALSE
 - hf_version: "2.1.1"  # Optional, character string. Defaults to the hf_version argument default in hfsubsetR::get_subset() function. The hydrofabric version.
 - domain: "conus"  # Optional, character string. Defaults to the hf_version argument default in hfsubsetR::get_subset() function. The hydrofabric domain.
 - type: "nextgen"  # Optional, character string. Defaults to the hf_version argument default in hfsubsetR::get_subset() function. The hydrofabric type.
 - lyrs: # Optional, sublist of character strings. Defaults to the hf_version argument default in hfsubsetR::get_subset() function. Hydrofabric layers to extract.
   - 'divides'
   - 'network'
 - source: "s3://lynker-spatial/hydrofabric"
attr_select: # The names of variable sublistings are standardized with _vars, e.g. ha_vars, usgs_vars, sc_vars
  - 's3_path_hydatl': '{s3_base}/hydroATLAS/hydroatlas_vars.parquet' # path to hydroatlas data formatted for hydrofabric. Required only if hydroatlas variables desired.
  - 'ha_vars':  # hydroatlas variables. Must specify s3_path_hydatl if desired.
    - 'pet_mm_s01'
    - 'cly_pc_sav'
    - 'cly_pc_uav'
  - 'usgs_vars': # list of variables retrievable using nhdplusTools::get_characteristics_metadata().
    - 'TOT_TWi'
    - 'TOT_PRSNOW'
    - 'TOT_POPDENS91'
    - 'TOT_EWT'
    - 'TOT_RECHG'
  - 'sc_vars': # Streamcat variables of interest. #TODO add streamcat grabber capability to proc.attr.hydfab
    - # In this example case, no streamcat variables selected
references: # All optional but **very** helpful metadata
  - 'input_filepath': '{base_dir}/julemai-xSSA/data_in/basin_metadata/basin_validation_results.txt'
  - 'source_url': 'https://zenodo.org/records/5730428'
  - 'dataset_doi': '10.5281/zenodo.5730428'
  - 'literature_doi': 'https://doi.org/10.1038/s41467-022-28010-7'
